# MNIST-Three-Layers-FNN-from-scratch

This FNN uses simple matrix multiplication, ReLU activation function, Softmax and CrossEntropy loss.

Weights were initialized with Xavier Initialization

Hyperparameters:
learning rate = 0.5, learning rate decay = 0.9, num of epochs = 8

The Network is 3 layers FNN and can be easily extended
